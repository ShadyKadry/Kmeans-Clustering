var documenterSearchIndex = {"docs":
[{"location":"internal/#KMeansClustering.KMedoids.KMedoids_fit","page":"-","title":"KMeansClustering.KMedoids.KMedoids_fit","text":"KMedoids_fit(data, n_clusters; init_method=:random, max_iter=100,\n             tol=1e-4, rng=Random.GLOBAL_RNG, distance_fun=(a,b)->sum((a .- b).^2))\n\nPerform K-Medoids clustering on a dataset.\n\nK-Medoids is a clustering algorithm similar to k-means, but cluster centers (medoids) are always chosen from actual data points, making the algorithm more robust to noise and outliers.\n\nImplementation is based on the description from: http://leicestermath.org.uk/KmeansKmedoids/Kmeans_Kmedoids.html\n\nArguments\n\ndata::AbstractMatrix     A matrix of size (n_features, n_samples) where columns are data points   and rows are features.\nn_clusters::Integer     Number of clusters (i.e. number of medoids to compute).\n\nKeyword Arguments\n\ninit_method::Symbol = :random     Method for choosing initial medoids. Currently supported: :random.\nmax_iter::Integer = 100     Maximum number of refinement iterations.\ntol::Real = 1e-4     Minimum improvement required for convergence.\nrng::AbstractRNG = Random.GLOBAL_RNG     Random number generator.\ndistance_fun::Function     A function dist(a, b) returning the distance between two sample vectors.   Default is squared Euclidean distance.\n\nReturns a KMeansResult\n\n\n\n\n\n","category":"function"},{"location":"internal/#KMeansClustering.AlgorithmsKMeansPP.kmeanspp_init","page":"-","title":"KMeansClustering.AlgorithmsKMeansPP.kmeanspp_init","text":"kmeanspp_init(X, k; rng=Random.GLOBAL_RNG)\n\nSelect k initial centers using the k-means++ heuristic.\n\nArguments\n\nX: data matrix with features in rows and observations in columns.\nk: number of clusters.\n\nKeyword arguments\n\nrng: random number generator.\n\nReturns A vector of length k with indices into the columns of X, indicating which points are chosen as initial centers.\n\n\n\n\n\n","category":"function"},{"location":"#KMeansClustering","page":"Home","title":"KMeansClustering","text":"Documentation for KMeansClustering.\n\nPages   = [\"index.md\"]","category":"section"},{"location":"#KMeansClustering.kmeans-Tuple{AbstractMatrix{<:Real}, Integer}","page":"Home","title":"KMeansClustering.kmeans","text":"kmeans(X, k; method=:kmeans, init=:random, maxiter=100, tol=1e-4, rng=Random.GLOBAL_RNG)\n\nHigh-level entry point for k-means clustering.\n\nArguments\n\nX: data matrix with features in rows and observations in columns.\nk: number of clusters.\n\nKeyword arguments\n\nmethod: algorithm selector, see below (:kmedoids)\ninit: initialization strategy (:random, :kmeanspp).\nmaxiter: maximum number of Lloyd iterations.\ntol: tolerance for convergence.\nrng: random number generator.\n\nReturns a KMeansResult.\n\nAvailable algorithms:\n\nK-Medoids (method=:kmedoids):   As described by E.M. Mirkes, K-means and K-medoids applet. University of Leicester, 2011   Unlike typical K-Means, K-Medoids chooses its cluster centers from the given points X instead of calculating    artificial ones.\n\n\n\n\n\n","category":"method"},{"location":"#KMeansClustering.KMeansResult","page":"Home","title":"KMeansClustering.KMeansResult","text":"KMeansResult\n\nThis type stores the outcome of a k-means clustering run.\n\nConventions:\n\nThe data matrix X is assumed to have observations in columns and features in rows:   size(X, 1) = number of features   size(X, 2) = number of points\nThe centers matrix follows the same convention: each column is a cluster center.\n\nFields:\n\ncenters::Matrix{T}   The final cluster centers as a dÃ—k matrix, where d is the number of features   and k is the number of clusters.\nassignments::Vector{Int}   Cluster assignment for each data point as a vector of length n, where   n is the number of points (columns of X). The i-th entry is an integer   in 1:k indicating the cluster index of point i.\ninertia::T   The sum of squared distances of each point to its assigned center   (within-cluster sum of squares), used as a measure of cluster quality.\niterations::Int   The number of iterations of the k-means update loop that were performed.\nconverged::Bool   Indicates whether the algorithm stopped because it met the convergence   criterion (true) or because it hit the maximum number of iterations (false).\ninit_method::Symbol   The initialization method used for the run, e.g. :random or :kmeanspp.\n\n\n\n\n\n","category":"type"}]
}
